{"./":{"url":"./","title":"关于DBhuang的技术日志","keywords":"","body":"markdown-note 当前文件夹记录着对每项技术的学习日志和工作过程遇到的问题的记录 "},"git/工作区与本地仓库.html":{"url":"git/工作区与本地仓库.html","title":"工作区与本地仓库","keywords":"","body":"一、工作区、缓存区、本地仓库 git不与远程仓库关联自己也有独立的版本管理功能，所以有无网络对本地的版本管理毫无影响，以下介绍以下这三者具体是什么东西： 工作区：粗暴的说就是你电脑的文件夹及你肉眼看到的文件 缓存区：工作区修改的文件不一定全部都提交的版本库，需要提交的先放到这里，其实缓存区也是版本库的一部分只为好理解虚拟的分出来 版本库：工作区有一个隐藏目录.git文件夹，这就是存储版本的地方 二、一个文件从工作区到本地版本库的过程 1、制造出一个工作区和版本库，随便找个地方右键打开git bash命令窗口（为了实验如果有本地仓库则忽略本操作）： $ mkdir hello_world #创建个文件夹 $ cd hello_world #进入到文件夹 $ git init #对hello_world文件夹初始化它的本地仓库，此时文件夹会多了.git文件夹即仓库 2、新建个文件并且写点内容进去并查看当前工作区的一个状态： $ echo \"我要写点内容到这个hello.txt文件并且放进仓库\" >> hello.txt $ git status On branch master No commits yet Untracked files: (use \"git add ...\" to include in what will be committed) hello.txt not 3、提交到缓存区并查看当前工作区的一个状态： $ git add . $ git status On branch master No commits yet Changes to be committed: (use \"git rm --cached ...\" to unstage) new file: hello.txt 4、提交到本地版本库并查看当前工作区的一个状态： $ git commit -m \"提交内容到本地仓库\" $ git status On branch master nothing to commit, working tree clean 5、至此其实已经文件放到了本地的版本库中，如果想偷懒其实可以把add和commit命令合并，单前提是文件已经存在于本地版本库否则会报错： $ git commit -am \"粗暴的把工作区的所有内容都提交到本地仓库\" 三、修改了（或者删除了且必须是手动删）工作区的文件想撤销 $ git status On branch master Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git checkout -- ...\" to discard changes in working directory) modified: hello.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") $ git checkout -- . 四、修改了（或者删除了且必须是手动删）工作区的文件并且提交到了缓冲区想撤销 $ git status On branch master Changes to be committed: (use \"git reset HEAD ...\" to unstage) modified: hello.txt 取版本库中的替换掉缓冲区的文件： $ git reset HEAD . 此时再看状态与【修改了工作区的文件想撤销】是一样的，所以要执行checkout即可把工作区的也撤销掉： $ git checkout -- . 五、文件已经提交到了本地版本库想删除掉 删除掉工作区的文件： $ git rm 提交代码到本地版本库 $ git commit -am \"备注\" 六、手动删除（操作右键的删除）和git rm删除的区别 手动删除--仅仅是删除了缓冲区： $ git status On branch master Changes not staged for commit: (use \"git add/rm ...\" to update what will be committed) (use \"git checkout -- ...\" to discard changes in working directory) deleted: hello.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") git rm 删除--删除工作区并且放到了缓冲区： $ git rm hello.txt $ git status On branch master Changes to be committed: (use \"git reset HEAD ...\" to unstage) deleted: hello.txt 七、手动删除的恢复其实和修改的恢复是一样的 $ git checkout -- . 八、git rm删除的恢复其实和修改的恢复是一样的 $ git reset HEAD . #或者（git reset HEAD hello.txt） $ git checkout -- . #或者（git checkout -- hello.txt） 九、切换版本 1、查看日志你会发现这个HEAD指向最新的一个版本中： $ git log --pretty=oneline #查看提交历史 0bf54f957cdb326c9a83904579ff87ff7df6639f (HEAD -> master) v1.3 404771100de2925884fa3a0b80eb6efd431a14b5 v1.2 280da6833d159c98fa0a55adef31b2612dc96c4d v1.1 4dbafbdff16d5ddec2283d14cd1e2fcc8421ad2a v1.0 $ git reflog #查看命令历史 0bf54f9 (HEAD -> master) HEAD@{0}: commit: v1.3 4047711 HEAD@{1}: commit: v1.2 280da68 HEAD@{2}: commit: v1.1 4dbafbd HEAD@{3}: commit (initial): v1.0 2、切换到v1.1版本（除了指定commit_id 还可以通过HEAD^^或HEAD~2）： $ git reset --hard 280da68 HEAD is now at 280da68 v1.1 $ git log --pretty=oneline 280da6833d159c98fa0a55adef31b2612dc96c4d (HEAD -> master) v1.1 4dbafbdff16d5ddec2283d14cd1e2fcc8421ad2a v1.0 $ git reflog 280da68 (HEAD -> master) HEAD@{0}: reset: moving to 280da68 0bf54f9 HEAD@{1}: commit: v1.3 4047711 HEAD@{2}: commit: v1.2 280da68 (HEAD -> master) HEAD@{3}: commit: v1.1 4dbafbd HEAD@{4}: commit (initial): v1.0 3、进行切换并修改 3.1、切换到v1.1版本，修改并提交会是怎么样一个状态呢： $ git log --pretty=oneline 7dae2d9ba2ade405b50dc39e5f845de4b93074ca (HEAD -> master) v1.4 280da6833d159c98fa0a55adef31b2612dc96c4d v1.1 4dbafbdff16d5ddec2283d14cd1e2fcc8421ad2a v1.0 $ git reflog 7dae2d9 (HEAD -> master) HEAD@{0}: commit: v1.4 280da68 HEAD@{1}: reset: moving to 280da68 0bf54f9 HEAD@{2}: commit: v1.3 4047711 HEAD@{3}: commit: v1.2 280da68 HEAD@{4}: commit: v1.1 4dbafbd HEAD@{5}: commit (initial): v1.0 3.2、切换到v1.1版本，再切换回v1.3，修改并提交会是怎么样一个状态呢： $ git reset --hard 0bf54f9 HEAD is now at 0bf54f9 v1.3 $ git log --pretty=oneline 0bf54f957cdb326c9a83904579ff87ff7df6639f (HEAD -> master) v1.3 404771100de2925884fa3a0b80eb6efd431a14b5 v1.2 280da6833d159c98fa0a55adef31b2612dc96c4d v1.1 4dbafbdff16d5ddec2283d14cd1e2fcc8421ad2a v1.0 $ git reflog 0bf54f9 (HEAD -> master) HEAD@{0}: reset: moving to 0bf54f9 280da68 HEAD@{1}: reset: moving to 280da68 0bf54f9 (HEAD -> master) HEAD@{2}: commit: v1.3 4047711 HEAD@{3}: commit: v1.2 280da68 HEAD@{4}: commit: v1.1 4dbafbd HEAD@{5}: commit (initial): v1.0 $ git log --pretty=oneline 5f753e93db1bfff417adbcd1c536caa7e3de948e (HEAD -> master) v1.4 0bf54f957cdb326c9a83904579ff87ff7df6639f v1.3 404771100de2925884fa3a0b80eb6efd431a14b5 v1.2 280da6833d159c98fa0a55adef31b2612dc96c4d v1.1 4dbafbdff16d5ddec2283d14cd1e2fcc8421ad2a v1.0 $ git reflog 5f753e9 (HEAD -> master) HEAD@{0}: commit: v1.4 0bf54f9 HEAD@{1}: reset: moving to 0bf54f9 280da68 HEAD@{2}: reset: moving to 280da68 0bf54f9 HEAD@{3}: commit: v1.3 4047711 HEAD@{4}: commit: v1.2 280da68 HEAD@{5}: commit: v1.1 4dbafbd HEAD@{6}: commit (initial): v1.0 十、比较工作区文件与版本库直接的差别 $ echo \"v1.5\" >> hello.txt $ git diff HEAD warning: LF will be replaced by CRLF in hello.txt. The file will have its original line endings in your working directory. diff --git a/hello.txt b/hello.txt index b750180..21bb40e 100644 --- a/hello.txt +++ b/hello.txt @@ -3,3 +3,4 @@ v1.1 v1.2 v1.3 v1.4 +v1.5 十一、学会通过看状态执行对应的操作 (use \"git add ...\" to include in what will be committed) (use \"git rm --cached ...\" to unstage) (use \"git reset HEAD ...\" to unstage) (use \"git add ...\" to update what will be committed) (use \"git checkout -- ...\" to discard changes in working directory) (use \"git reset HEAD ...\" to unstage) (use \"git add/rm ...\" to update what will be committed) 十二、本章节需要掌握的命令 $ git add 添加工作区文件到缓冲区 $ git commit -m \"\" 添加缓冲区文件到本地仓库并且必须带上注释 $ git commit -am \"\" 把工作区变更的内容全部提交到本地仓库修改文件可用，第一次添加时候（即版本库还有这文件）不能用会报错 $ git status 查看工作区的文件状态 $ git reset HEAD 丢弃缓冲区的修改(把暂存区的修改回退到工作区,HEAD表示最新的版本) $ git cheackout -- 撤销文件在工作区的全部修改,--很重要没有了就变成了切换分支 $ git log 查看提交历史本地版本库完整日志信息 $ git log --pretty=oneline 查看提交历史本地版本库简要日志信息 $ git reflog 查看命令历史 $ git reset --hard 切换到指定的版本 $ git diff HEAD 比较本地版本库中代码与工作区的区别 十三、本章愿景 学会工作区和本地版本库之间文件的增减，修改，删除及恢复，HEAD代表什么，checkout中的--有什么作用。 "},"git/本地仓库到远程仓库.html":{"url":"git/本地仓库到远程仓库.html","title":"本地仓库到远程仓库","keywords":"","body":"一、工作区到远程仓库之间的关系 《工作区》 gitadd-->> 《缓冲区》 gitcommit-->> 《本地仓库》 gitpush-->> 《远程仓库》 二、账号密码与公钥私钥怎么对应http协议和ssh协议使用 0、远程仓库如： github gitee（码云） gitlab 1、远程仓库地址有两种协议类型： http协议：https://github.com/dbhuang/dbhuang.github.io.git ssh协议：git@github.com:dbhuang/dbhuang.github.io.git 2、确保能拉推成功此时必须是要本地与远程仓库用户权限验证通过，使用的协议决定你的方式： http协议：拉推的时候需要你填用户名密码，当然这个可配置存储起来使推和拉时候不需要再次填 ssh协议：拉推的时候不需要填任何东西，但需要你生成公钥私钥并把公钥配置在远程仓库中 3、配置账号使本地仓库与远程仓库拉推不需要任何验证 http协议： 第一次输入账号密码时候，执行以下的语句即可把登录信息记录起来 $ git config --global credential.helper store #永久记住密码 $ git config –global credential.helper cache #默认记住15分钟 $ git config credential.helper 'cache –timeout=3600'#自定义配置记住1小时 丢弃存储的密码 $ git config --system --unset credential.helper ssh协议： #使用ssh协议必须必须要设置user.name和user.email让远程仓库知道你是谁 $ git config --global user.name \"名字\" $ git config --global user.email \"邮箱\" $ ssh-keygen -t rsa -C \"邮箱\" #【邮箱】必须与git config --global user.email 设置的一样 #此时会生成两个文件在.ssh目录下：id_rsa是私钥id_rsa.pub是公钥 #打开并复制公钥的内容，粘贴到远程服务器的ssh and GPG keys列表中 #在每次的拉推私钥就起到了一个密码的作用自动被远程仓库用来验证 github使用ssh协议会出现的事情： 需要你通过官网验证是否真的是github官方仓库RSA Key的指纹信息 The authenticity of host 'github.com (13.250.177.223)' can't be established. RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8. Are you sure you want to continue connecting (yes/no)? github第一次推的时候会有一个安全提醒： Warning: Permanently added 'github.com,192.30.255.113' (RSA) to the list of known hosts. 本地项目为空 【 把远程仓库内容拉取到本地： $ git clone 【远程仓库地址】 根据使用的协议关联好账号密码或者公钥私钥 然后即可进行本地与远程仓库正常的 pull push 三、本地项目不为空 【>>推>>】 远程仓库为空: 初始化： $ git init 把工作区的（所有）代码提交到缓存区： $ git add . 把缓存区的代码提交到本地仓库： $ git commit -m \"此处备注必须填写\" 给远程仓库弄一个别名绑定（一般都命名为origin）： $ git remote origin 【远程仓库http协议地址或ssh协议地址】 根据使用的协议关联好账号密码或者公钥私钥 然后即可进行本地与远程仓库正常的 pull push 把本地仓库master分支代码推到远程仓库origin（刚刚在上面定义的别名） $ git push origin master 如果采用的是http协议上面这个推动作会提示叫你输入账号和密码才能完成推送 如果才用的是ssh协议，则需要配置好公钥私钥才能推送成功 另外多人协助请先拉再推 git pull 当第一次推的时候带上-u参数,git不但会把本地的master分支内容推送的远程分支，还会把本地的master分支和远程的分支关联起来 $ git push -u origin master 由于上面的第一次push带了-u建立好了关系，下次可简写即可把本地内容推送到远程 $ git push 四、本地一套代码想要存到多个远程仓库怎么办 ？ 如果没有添加过任何的远程仓库地址,别名分别是github_origin 和 gitee_origin： $ git remote add github_origin git@github.com:dbhuang/dbhuang.github.io.git $ git remote add gitee_origin git@gitee.com:dbhuang/dbhuang.github.io.git 查看目前的远程仓库有哪些（目前只要github的）： $ git remote -v gitee_origin git@gitee.com:dbhuang/dbhuang.github.io.git (fetch) gitee_origin git@gitee.com:dbhuang/dbhuang.github.io.git (push) github_origin git@github.com:dbhuang/dbhuang.github.io.git (fetch) github_origin git@github.com:dbhuang/dbhuang.github.io.git (push) origin git@github.com:dbhuang/dbhuang.github.io.git (fetch) origin git@github.com:dbhuang/dbhuang.github.io.git (push) 添加完远程仓库的别名只是为了push时候写少点内容： $ git push 把本地的master分支推送到github上去 $ git push github_origin master 把本地的master分支推送到gitee上去 $ git push gitee_origin master 如果想删除别名 $ git remote remove 因为当前其实是针对github设置了两个别名(origin与github_origin)所以提交到github也可简写为以下两种写法 $ git push #推送到远程分支默认就是用远程的origin和本地的master且origin设定的是github的地址 $ git push origin master #因为origin设定的是github的地址 五、想把本地仓库中的代码提交到远程仓库但是工作区有修改过的代码 此时执行push提交到远程是会报错说你工作区还有代码未提交到本地仓库，需要把工作区的内容藏匿起来： $ git stash 执行完push操作后取回最近一次藏匿的代码到工作区中 ： $ git stash pop 如果你藏匿了好几个，不是回复最近的一个，查看所有的藏匿内容，然后指定： $ git stash list 查看藏匿内容列表 $ git stash apply stash@{0} 恢复之前藏匿的内容 $ git stash drop 删除藏匿内容列表 六、本章需要好好掌握的几个git命令 $ git config --global user.name \"名字\" 设置当前使用者名称 $ git config --global user.email \"邮箱\" 设置当前使用者邮箱 $ git clone 克隆远程仓库代码到本地 $ git add 添加工作区文件到缓冲区 $ git commit -m \"\" 添加缓冲区文件到本地仓库并且必须带上注释 $ git remote add 远程仓库添加别名 $ git remote -v 查看本地设置了那些远程仓库的别名及对应远程地址 $ git pull 拉取远程仓库代码到本地并与本地仓库代码合并 $ git push 推送本地仓库代码到远程仓库 $ git stash list 查看藏匿内容列表 $ git stash apply stash@{0} 恢复之前藏匿的内容 $ git stash drop 删除藏匿内容列表 $ git stash 藏匿内容 $ git stash pop 恢复最新藏匿的内容并删除该藏匿记录 七、本章的愿景 看完本章后，是希望对工作区 缓冲区 本地仓库 远程仓库有初步的认识，因为本章重点要知道怎么才能把本地仓库与远程仓库关联起来 "},"git/本地分支和远程分支.html":{"url":"git/本地分支和远程分支.html","title":"本地分支和远程分支","keywords":"","body":"项目开发中，当远程分支有变动，有人增加或删除了某些分支，而自己本地没有及时自动刷新出来分支的时候，可以用以下命令来更新以下分支信息 git fetch origin --prune git fetch ：此命令会到远程仓库中拉取对应你本地仓库中还没有的数据。 git fetch 将某个远程主机的更新，全部取回本地.但注意它只是把远程分支在你本地对应的分支上的数据更新了，你本地的库里面还是没有任何数据的。比如：我已在远程库修改了Test.txt 注意：所取得的远程分支在本地主机上要用\"远程主机名/分支名\"的形式读取。比如origin主机的master，就要用 origin/master读取。 git checkout dev //切换分支dev git branch dev //创建本地分支 git checkout -b dev //创建本地分支并切换 git branch -av //查看本地及远程的所有分支 git branch -vv //查看本地分支与远程分支的关系 git push --set-upstream origin dev //远程没有dev分支，把本地dev分支关联到远程，执行后相当于创建了一个名叫dev的远程分支。 git stash //藏匿工作区的修改内容 git stash pop //恢复藏匿列表最新的一条记录，并删除这条记录 git stash list //查看藏匿列表 git marget dev //在当前分支上去拿dev的内容合并过来 git fetch origin //更新远程新增分支到本地 git fetch origin --prune //同步远程的分支情况 查看分支：git branch 创建分支：git branch 切换分支：git checkout 创建+切换分支：git checkout -b 合并某分支到当前分支：git merge 删除分支：git branch -d 一、克隆分支 例如，从git@git.qhdsx.com:bitgk/sx-mall.git 远端仓库克隆 dev 分支。 ## git clone -b git clone -b dev git@git.qhdsx.com:bitgeek/sx-mall.git 二、Fetch 例如，从远端仓库拉取 dev 分支到本地。 ## git fetch origin git fetch origin dev 三、Checkout 例如，创建的dev分支就是刚刚从远程版本库中拉取的dev分支，并切换到dev分支上进行开发 ## git checkout -b origin/ git checkout -b dev origin/dev "},"git/gitflow工作流.html":{"url":"git/gitflow工作流.html","title":"gitflow工作流","keywords":"","body":" Git分支类型 「master 分支」 master 为产品主分支，该分支为只读唯一分支，也是用于部署生产环境的分支，需确保master分支的稳定性。 master 分支一般由release分支或hotfix分支合并，任何情况下都不应该直接修改master分支代码。 产品的功能全部实现后，最终在master分支对外发布，另外所有在master分支的推送应该打标签（tag）做记录，方便追溯。 master 分支不可删除。 develop 分支 develop 为主开发分支，基于master分支创建，始终保持最新完成功能的代码以及bug修复后的代码。 develop 分支为只读唯一分支，只能从其他分支合并，不可以直接在该分支做功能开发或bug修复。 一般开发新功能时，feature分支都是基于develop分支下创建的。 develop 分支包含所有要发布到下一个release的代码。 feature功能分支完成后, 开发人员需合并到develop分支(不推送远程)，需先将develop分支合并到feature，解决完冲突后再合并到develop分支。 当所有新功能开发完成后，开发人员并自测完成后，此时从develop拉取release分支，进行提测。 release或hotfix 分支上线完成后, 开发人员需合并到develop分支并推送远程。 develop 分支不可删。 feature 分支 feature 分支通常为新功能或新特性开发分支，以develop分支为基础创建feature分支。 分支命名: feature/ 开头的为新特性或新功能分支，建议的命名规则: feature/user_createtime_feature，例如：feature/ftd_20201018_alipay，含义为：开发人员ftd在2020年10月18日时创建了一个支付宝支付的功能分支。 新特性或新功能开发完成后，开发人员需合到develop分支。 feature 分支可同时存在多个，用于团队中多个功能同时开发。 feature 分支属于临时分支，功能完成后可选删除。 release 分支 release 分支为预上线分支，基于本次上线所有的feature分支合并到develop分支之后，从develop分支创建。 分支命名: release/ 开头的为预上线分支，建议的命名规则: release/version_publishtime，例如：release/v2.1.1_20201018，含义为：版本号v2.1.1计划于2020年10月18日时发布。 release 分支主要用于提交给测试人员进行功能测试。发布提测阶段，会以release分支代码为基准进行提测。测试过程中发现的bug在本分支进行修复，上线完成后需合并到develop/master分支并推送远程。 release 分支属于临时分支，产品上线后可选删除。 ❝ 当有一组feature开发完成后，首先开发人员会各自将最新功能代码合并到develop分支。进入提测阶段时，开发组长在develop分支上创建release分支。 如果在测试过程中发现bug需要修复，则直接由开发者在release分支修复并提交。当测试完成后，开发组长将release分支合并到master和develop分支，此时master为最新可发布代码，用作产品发布上线。 ❞ hotfix 分支 hotfix 分支为线上bug修复分支或叫补丁分支，主要用于对线上的版本进行bug修复。 分支命名: hotfix/ 开头的为修复分支，它的命名规则与 feature 分支类似，建议的命名规则: hotfix/user_createtime_hotfix，例如：hotfix/ftd_20201018_alipaybugfix，含义为：开发人员ftd在2020年10月18日时创建了一个支付宝支付bug修复的分支。 hotfix 分支用于线上出现紧急问题时，需要及时修复，以master分支为基线，创建hotfix分支。当问题修复完成后，需要合并到master分支和develop分支并推送远程。 所有hotfix分支的修改会进入到下一个release。 hotfix 分支属于临时分支，bug修复上线后可选删除。 "},"git/百兆大文件提交.html":{"url":"git/百兆大文件提交.html","title":"百兆大文件提交","keywords":"","body":" 下载git large file storage https://git-lfs.github.com/ 在要使用Git LFS的每个Git存储库中，选择要由Git LFS管理的文件类型（或直接编辑.gitattributes）。您可以随时配置其他文件扩展名。 git lfs track“ * .psd” 现在确保.gitattributes被跟踪： git add .gitattributes 像往常一样提交并推送到GitHub。 git add file.psd git commit -m \"Add design file\" git push origin master "},"git/获取版本间差异文件上线.html":{"url":"git/获取版本间差异文件上线.html","title":"获取版本间差异文件上线","keywords":"","body":"开发环境->内网测试环境->外网UAT环境->正式环境 0、进入到项目目录 [root@localhost /]# cd /data/xiaochengxu/ [root@localhost xiaochengxu]# pwd /data/xiaochengxu 1、获取修改记录日志 [root@localhost xiaochengxu]# git log --pretty=oneline 6cd45627660ac8a271e1fecfafbf9792c766d97c 把2.5.36bat版更新为2.5.36发布版 00a6499b3c8efafcb8388f7a0a6e7991d7a5b9a2 小程序配置修改，详情接口按需修改 7155cb7f42677a124b5aafd7497d7c19ae42646e '首页登录获取token' ae4dec4a8be04fea456b564f93f64bf9b24ef5f0 '引入jwt插件' 59277c5e8b3890c7ac98ca06b6bf32239251dc3c '把配置文件编程自动适应线上线下模式' 3b011131e76552974fcc6c82e4ff3c5566354d09 更改小程序配置和站点配置并生成1.1.0sql和配置所需证书 f381ce5d31280cc0360952fa1e3426a04bcf1b3d '调用install生成内容' 9291edc896d71a5905894efc8a33aeb255e616e6 加入2.5.36更替的内容 ec79ea3a23eabb9d5f9d7243cc0c8a69bca05c7f '初始化' 2、比较版本之间的差异文件 [root@localhost xiaochengxu]# sudo git diff 6cd456 7155cb --name-only application/admin/controller/order/StoreOrder.php application/admin/controller/ump/StoreBargain.php application/routine/controller/AuthApi.php application/routine/model/store/StoreBargainUser.php application/wechat/controller/Home.php application/wechat/model/store/StoreBargainUser.php update_log.txt vendor/overtrue/wechat/src/Core/Http.php view/crmebN/app.js view/crmebN/pages/cut-list/cut-list.js view/crmebN/pages/cut-one/cut-one.wxml view/crmebN/pages/index/index.wxss view/crmebN/pages/loading/loading.js view/crmebN/pages/loading/loading.json view/crmebN/pages/loading/loading.wxml view/crmebN/pages/loading/loading.wxss view/crmebN/pages/product-con/index.wxss view/crmebN/pages/user/user.js view/crmebN/project.config.json view/crmebN/wxParse/wxParse.wxss 3、把这些文件打包到一个压缩包 [root@localhost xiaochengxu]# sudo git diff 6cd456 7155cb --name-only | xargs tar -czvf ../update-20190322.tar.gz application/admin/controller/order/StoreOrder.php application/admin/controller/ump/StoreBargain.php application/routine/controller/AuthApi.php application/routine/model/store/StoreBargainUser.php application/wechat/controller/Home.php application/wechat/model/store/StoreBargainUser.php update_log.txt vendor/overtrue/wechat/src/Core/Http.php view/crmebN/app.js view/crmebN/pages/cut-list/cut-list.js view/crmebN/pages/cut-one/cut-one.wxml view/crmebN/pages/index/index.wxss view/crmebN/pages/loading/loading.js view/crmebN/pages/loading/loading.json view/crmebN/pages/loading/loading.wxml view/crmebN/pages/loading/loading.wxss view/crmebN/pages/product-con/index.wxss view/crmebN/pages/user/user.js view/crmebN/project.config.json view/crmebN/wxParse/wxParse.wxss 4、在测试环境把压缩包上传到服务器(提示中需要输入密码) [root@localhost xiaochengxu]# scp /data/update-20190322.tar.gz root@192.168.1.111:/data/update_gz The authenticity of host '192.168.1.111 (192.168.1.111)' can't be established. ECDSA key fingerprint is SHA256:6O2nNs2xZ8UZndt7Av+zo/bX91kW23ELg+m9zZdX/kg. ECDSA key fingerprint is MD5:df:e2:82:a9:82:32:90:29:9a:f7:d0:c6:23:96:ad:c3. Are you sure you want to continue connecting (yes/no)? yes root@192.168.1.111's password: update-20190322.tar.gz 100% 139KB 4.0MB/s 00:00 5、登录UAT服务器并解压覆盖（此处tar -m忽略时间差） [root@hello update_gz]# tar -zxvmf /data/update_gz/update-20190322.tar.gz -C /data/a.com application/admin/controller/order/StoreOrder.php application/admin/controller/ump/StoreBargain.php application/routine/controller/AuthApi.php application/routine/model/store/StoreBargainUser.php application/wechat/controller/Home.php application/wechat/model/store/StoreBargainUser.php update_log.txt vendor/overtrue/wechat/src/Core/Http.php view/crmebN/app.js view/crmebN/pages/cut-list/cut-list.js view/crmebN/pages/cut-one/cut-one.wxml view/crmebN/pages/index/index.wxss view/crmebN/pages/loading/loading.js view/crmebN/pages/loading/loading.json view/crmebN/pages/loading/loading.wxml view/crmebN/pages/loading/loading.wxss view/crmebN/pages/product-con/index.wxss view/crmebN/pages/user/user.js view/crmebN/project.config.json view/crmebN/wxParse/wxParse.wxss 6、从UAT服务器环境SYNC覆盖正式服务器，sync 自动同步脚本 "},"gitbook/搭建和使用.html":{"url":"gitbook/搭建和使用.html","title":"搭建和使用","keywords":"","body":"基础条件 安装node $ node -v v16.14.2 $ npm -v 8.5.0 gitbook安装 安装gitbookcli $ npm instal gitbook-cli -g 查看gitbook版本 $ gitbook -V CLI version: 2.3.2 GitBook version: 3.2.3 gitbook使用 初始化 $ gitbook init warn: no summary file in this book info: create SUMMARY.md info: initialization is finished 目录结构 ├─markdown-note │ ├─git git相关的md文件 │ ├─... 其他内容 │ ├─style │ │ └─website.css 自定义样式 │ ├─README.md 介绍 │ ├─SUMMARY.md gitbook目录结构 │ └─book.json json文件需要自己建，是一个配置文件 $ vim ./style/website.css /**不显示gitbook链接**/ .gitbook-link { display: none !important; } /**内容宽度**/ .page-inner { max-width: 90%; padding: 2px 2px 2px 2px; } .book .book-summary .book-logo { text-align: left !important; padding: 0px 0px !important; display: block !important; } /**代码背景和字体颜色以及行号**/ .page-inner .code-wrapper pre > code > span.code-line:before{ color: #a688888c; } .code-wrapper pre{ background: #f3f3f3; color: #333; } /**以下是滚动条样式**/ ::-webkit-scrollbar { background: #a4b7cf; border-radius: 0; height: 3px; position: absolute; width: 3px } ::-webkit-scrollbar-thumb { background: #4d7fbf; border-radius: 3px; -webkit-transition: all .25s ease-out; -o-transition: all .25s ease-out; transition: all .25s ease-out; } 编辑SUMMARY.md并生成对应目录md文件 * [关于DBhuang的技术日志](README.md) * [appium](appium/README.md) * [appium环境安装](appium/环境安装.md) * gitbook * [搭建和使用](gitbook/搭建和使用.md) ... # 编辑完SUMMARY.md文件后执行gitbook init 会创建不存在的文件 编译成静态文件 # gitbook build 启动服务 # gitbook serve 效果 gitbook配置文件值book.json 写好下面的json配置，需要执行命令来安装插件（这里下载插件需要一点时间，耐心等待即可） 参考网址：https://www.mapull.com/gitbook/comscore/ # gitbook install \"plugins\": [ \"-sharing\", # 移除分享 \"-lunr\", \"-search\",\"search-pro\", # 去除默认搜索，搜索关键字会高亮 \"expandable-chapters-small\", # 菜单折叠，去出-small下拉图标变大点 \"tbfed-pagefooter\", # 页脚 \"back-to-top-button\", # 回到顶部 \"copy-code-button\", # \"复制代码\" \"code\", #会在console打印信息 \"splitter\", # 调整菜单和内容的左右宽度 \"ancre-navigation\", # 悬浮本文菜单返回顶部 \"auto-scroll-table\", # 超长表格滚动 \"hide-element\", # 隐藏菜单底部的gitbook ] { \"title\": \"DBhuang的技术日志\", \"description\": \"一点点的积累\", \"author\": \"dbhuang\", \"output.name\": \"site\", \"language\": \"zh-hans\", \"gitbook\": \"3.2.3\", \"root\": \".\", \"plugins\": [ \"-lunr\", \"-search\", \"-sharing\", \"-default-theme\", \"search-pro\", \"theme-comscore\", \"splitter\", \"tbfed-pagefooter\", \"expandable-chapters\", \"hide-element\", \"-highlight\",\"prism\",\"prism-themes\", \"code\", \"ancre-navigation\" ], \"pluginsConfig\": { \"tbfed-pagefooter\": { \"copyright\":\"Copyright &copy dbhuang.com 2022\", \"modify_label\": \"该文件修订时间：\", \"modify_format\": \"YYYY-MM-DD HH:mm:ss\" }, \"hide-element\": { \"elements\": [\".gitbook-link\"] }, \"page-toc-button\": { \"maxTocDepth\": 2, \"minTocSize\": 2 }, \"prism\":{ \"css\":[ \"prism-themes/themes/prism-darcula.css\" ] } }, \"styles\": { \"website\": \"styles/website.css\", \"ebook\": \"styles/ebook.css\", \"pdf\": \"styles/pdf.css\", \"mobi\": \"styles/mobi.css\", \"epub\": \"styles/epub.css\" } } 错误解决 gitbook install遇到错误 # node -v v12.0.0 # 此版本gitbook install 遇到了错误，所以升级到了v16.14.2 info: installing 13 plugins using npm@3.9.2 info: info: installing plugin \"code\" # Fatal error in , line 0 # Check failed: U_SUCCESS(status). #FailureMessage Object: 0x7ffeefbf5ec0Illegal instruction: 4 GitBook默认主题报错 theme.js:4 Uncaught TypeError: Cannot read property 'split' of undefined 参考网址：https://gitee.com/zhousiwei/bootplus/blob/master/gitbook.md   在使用该主题的过程中，发现经常会在控制台报下面的错误，没有找到是哪里的原因，官方也一直没有修复。   转到用户目录并打开文件.gitbook/versions/3.2.3/node_modules/gitbook-plugin-theme-default/src/js/theme/navigation.js，找到getChapterHash函数，替换以下内容, 回到 gitbook-plugin-theme-default 文件夹，运行 npm install 重新编译文件。 // var $link = $chapter.children('a'), // hash = $link.attr('href').split('#')[1]; // if (hash) hash = '#'+hash; // return (!!hash)? hash : ''; var $link = $chapter.children('a'), hash, href, parts; if ($link.length) { href = $link.attr('href') if (href) { parts = href.split('#'); if (parts.length>1) { hash = parts[1]; } } } if (hash) hash = '#'+hash; return (!!hash)? hash : ''; # 如果在/.gitbook/versions/3.2.3/node_modules/gitbook-plugin-theme-default内执行npm install失败 # 则回到/.gitbook/versions/3.2.3/node_modules/目录npm install gitbook-plugin-theme-default $ npm install > gitbook-plugin-theme-default@1.0.7 prepublish > ./src/build.sh '.' is not recognized as an internal or external command, operable program or batch file. npm ERR! code 1 npm ERR! path C:\\Users\\admin\\.gitbook\\versions\\3.2.3\\node_modules\\gitbook-plugin-theme-default npm ERR! command failed npm ERR! command C:\\Windows\\system32\\cmd.exe /d /s /c ./src/build.sh # 可能因为缺少全局扩展报错 admin@DESKTOP-A6LCTP1 MINGW64 ~/.gitbook/versions/3.2.3/node_modules/gitbook-plugin-theme-default $ ./src/build.sh ./src/build.sh: line 11: browserify: command not found ./src/build.sh: line 11: uglifyjs: command not found ./src/build.sh: line 12: browserify: command not found ./src/build.sh: line 12: uglifyjs: command not found ./src/build.sh: line 15: lessc: command not found ./src/build.sh: line 18: lessc: command not found ./src/build.sh: line 19: lessc: command not found ./src/build.sh: line 20: lessc: command not found ./src/build.sh: line 21: lessc: command not found $ npm install browserify -g $ npm install uglify-js -g $ npm install less@2.7.1 -g #不指定版本会说过高Unable to load plugin clean-css please make sure that it is installed under or at the same level as less 2.7.1 是从package.json中看到的 node版本问题导致graceful-fs报错 由于gitbook官方早就弃用gitbook-cli了，所以出现Bug大部分都是自己修改源码。 如果可以，可能需要fork gitbook-cli来维护它 官方原文：https://github.com/GitbookIO/gitbook#%EF%B8%8F-deprecation-warning node高版本问题（目前大概问题是出现在node12.18.3问题之后） 报错原文参考： C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\gitbook-cli\\node_modules\\npm\\node_modules\\graceful-fs\\polyfills.js:287 if (cb) cb.apply(this, arguments) ^ TypeError: cb.apply is not a function at C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\gitbook-cli\\node_modules\\npm\\node_modules\\graceful-fs\\polyfills.js:287:18 at FSReqCallback.oncomplete (fs.js:177:5) node -v 16.14.2 npm -v 8.5.0 node -v 17.9.0 npm -v 8.7.0 cd C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\gitbook-cli\\node_modules\\npm\\node_modules 我试着安装graceful-fs@latest(graceful-fs@4.2.10)，但安装完后，Gitbook就不见了。 最后，安装了graceful-fs@4.2.0来解决这个问题 找到NPM的全局安装目录 : (prefix就是全局安装路径) C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\gitbook-cli\\node_modules\\npm\\node_modules>npm config ls ; \"builtin\" config from C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\npm\\npmrc prefix = \"C:\\Users\\admin\\AppData\\Roaming\\npm\" ; \"user\" config from C:\\Users\\admin.npmrc registry = \"https://registry.npm.taobao.org/\" ; node bin location = C:\\Program Files\\nodejs\\node.exe ; node version = v17.9.0 ; npm local prefix = C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\gitbook-cli\\node_modules\\npm ; npm version = 8.7.0 ; cwd = C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\gitbook-cli\\node_modules\\npm\\node_modules ; HOME = C:\\Users\\admin ; Run npm config ls -l to show all defaults. "},"kafka/调整副本.html":{"url":"kafka/调整副本.html","title":"调整副本","keywords":"","body":"对已创建的topic调整副本数量 创建了topic时候没有指定多少个副本，或者增加了机器，需要调整副本 创建新topic，只限定1个副本 [root@centos2 ~]# /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper 192.168.1.160:2181 --replication-factor 1 --partitions 5 --topic click_log_1 WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both. Created topic click_log_1. # 指定一个副本，当前服务有两个broker可用 --replication-factor 1 # 指定五个partition --partitions 5 # 指定topic名字 --topic click_log_1 副本能设置多大值取决于broker数量，而查询可用的broker大概有两种方式 查询允许配置的zookeeper.connect 一般每个zookeeper对应一台（不准确） [root@centos2 ~]# cat /usr/local/kafka/config/server_9093.properties |grep \"zookeeper\" # Zookeeper connection string (see zookeeper docs for details). zookeeper.connect=192.168.1.160:2181,192.168.1.250:2181 # Timeout in ms for connecting to zookeeper zookeeper.connection.timeout.ms=18000 直接去zookeeper上面查 [root@centos2 ~]# cd /usr/local/zookeeper/bin [root@centos2 bin]# /usr/local/zookeeper/bin/zkCli.sh Connecting to localhost:2181 [zk: localhost:2181(CONNECTED) 0] ls ls [-s] [-w] [-R] path [zk: localhost:2181(CONNECTED) 1] ls / [admin, brokers, cluster, config, consumers, controller, controller_epoch, feature, isr_change_notification, latest_producer_id_block, log_dir_event_notification, zookeeper] [zk: localhost:2181(CONNECTED) 2] ls /brokers [ids, seqid, topics] [zk: localhost:2181(CONNECTED) 3] ls /brokers/ids [2,3] 查看topic副本情况 [root@centos2 ~]# /usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper=localhost:2181 --topic click_log_1 Topic: click_log_1 TopicId: 7obJqZM9TW6r75PMixCpnw PartitionCount: 5 ReplicationFactor: 1 Configs: Topic: click_log_1 Partition: 0 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log_1 Partition: 1 Leader: 2 Replicas: 2 Isr: 2 Topic: click_log_1 Partition: 2 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log_1 Partition: 3 Leader: 2 Replicas: 2 Isr: 2 Topic: click_log_1 Partition: 4 Leader: 3 Replicas: 3 Isr: 3 \"leader\" is the node responsible for all reads and writes for the given partition. Each node will be the leader for a randomly selected portion of the partitions. \"replicas\" is the list of nodes that replicate the log for this partition regardless of whether they are the leader or even if they are currently alive. \"isr\" is the set of \"in-sync\" replicas. This is the subset of the replicas list that is currently alive and caught-up to the leader. “leader”是负责给定分区的所有读取和写入的节点。每个节点将成为随机选择的分区部分的领导者。 “replicas”是复制此分区的日志的节点列表，无论它们是领导者还是当前处于活动状态。 “isr”是一组“同步”副本。这是副本列表的子集，当前处于活动状态并赶上了领导者。 模拟真实环境下，有数据被消费有数据未消费情况 #生产数据 [root@centos2 ~]# /usr/local/kafka/bin/kafka-console-producer.sh --broker-list 192.168.1.160:9093 --topic click_log_1 >a >b >c >d #消费数据 [root@centos2 ~]# /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.160:9093 --from-beginning --topic click_log_1 --group groupclicklog1 a b c d Processed a total of 4 messages # 再生产数据 [root@centos2 ~]# /usr/local/kafka/bin/kafka-consproducer.sh --broker-list 192.168.1.160:9093 --topic click_log_1 >e >f >g >h # 查看消费组目前的消费和未消费情况 [root@centos2 ~]# /usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.1.160:9093 --list 0 groupclicklog1 [root@centos2 ~]# /usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.1.160:9093 --describe --group groupclicklog1 Consumer group 'groupclicklog1' has no active members. GROUP TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-ID groupclicklog1 click_log_1 1 2 3 1 - - - groupclicklog1 click_log_1 2 2 3 1 - - - groupclicklog1 click_log_1 3 0 0 0 - - - groupclicklog1 click_log_1 4 0 2 2 - - - groupclicklog1 click_log_1 0 0 0 0 - - - 调整副本 # 调整前 [root@centos2 ~]# /usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper=localhost:2181 --topic click_log_1 Topic: click_log_1 TopicId: 7obJqZM9TW6r75PMixCpnw PartitionCount: 5 ReplicationFactor: 1 Configs: Topic: click_log_1 Partition: 0 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log_1 Partition: 1 Leader: 2 Replicas: 2 Isr: 2 Topic: click_log_1 Partition: 2 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log_1 Partition: 3 Leader: 2 Replicas: 2 Isr: 2 Topic: click_log_1 Partition: 4 Leader: 3 Replicas: 3 Isr: 3 # 编辑调整的json [root@centos2 ~]# cat replica.json { \"version\": 1, \"partitions\": [ {\"topic\": \"click_log_1\", \"partition\": 0,\"replicas\": [3,2]}, {\"topic\": \"click_log_1\", \"partition\": 1,\"replicas\": [2,3]}, {\"topic\": \"click_log_1\", \"partition\": 2,\"replicas\": [3,2]}, {\"topic\": \"click_log_1\", \"partition\": 3,\"replicas\": [2,3]}, {\"topic\": \"click_log_1\", \"partition\": 4,\"replicas\": [3,2]} ] } [root@centos2 ~]# /usr/local/kafka/bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file ~/replica.json --execute Warning: --zookeeper is deprecated, and will be removed in a future version of Kafka. Current partition replica assignment {\"version\":1,\"partitions\":[{\"topic\":\"click_log_1\",\"partition\":0,\"replicas\":[3],\"log_dirs\":[\"any\"]},{\"topic\":\"click_log_1\",\"partition\":1,\"replicas\":[2],\"log_dirs\":[\"any\"]},{\"topic\":\"click_log_1\",\"partition\":2,\"replicas\":[3],\"log_dirs\":[\"any\"]},{\"topic\":\"click_log_1\",\"partition\":3,\"replicas\":[2],\"log_dirs\":[\"any\"]},{\"topic\":\"click_log_1\",\"partition\":4,\"replicas\":[3],\"log_dirs\":[\"any\"]}]} Save this to use as the --reassignment-json-file option during rollback Successfully started partition reassignments for click_log_1-0,click_log_1-1,click_log_1-2,click_log_1-3,click_log_1-4 # 调整成功后 [root@centos2 ~]# /usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper=localhost:2181 --topic click_log_1 Topic: click_log_1 TopicId: 7obJqZM9TW6r75PMixCpnw PartitionCount: 5 ReplicationFactor: 2 Configs: Topic: click_log_1 Partition: 0 Leader: 3 Replicas: 3,2 Isr: 3,2 Topic: click_log_1 Partition: 1 Leader: 2 Replicas: 2,3 Isr: 2,3 Topic: click_log_1 Partition: 2 Leader: 3 Replicas: 3,2 Isr: 3,2 Topic: click_log_1 Partition: 3 Leader: 2 Replicas: 2,3 Isr: 2,3 Topic: click_log_1 Partition: 4 Leader: 3 Replicas: 3,2 Isr: 3,2 启动消费者对刚刚的未数据进行消费观察是否有影响 # 接着消费未消费的数据 [root@centos2 ~]# /usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.1.160:9093 --describe --group groupclicklog1 Consumer group 'groupclicklog1' has no active members. GROUP TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-ID groupclicklog1 click_log_1 1 2 3 1 - - - groupclicklog1 click_log_1 2 2 3 1 - - - groupclicklog1 click_log_1 3 0 0 0 - - - groupclicklog1 click_log_1 4 0 2 2 - - - groupclicklog1 click_log_1 0 0 0 0 - - - [root@centos2 ~]# /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.160:9093 --from-beginning --topic click_log_1 --group groupclicklog1 e f g h Processed a total of 4 messages # 新弄一个消费者组重开头消费数据 [root@centos2 ~]# /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.160:9093 --from-beginning --topic click_log_1 --group groupclicklog1-1 a b g e f c d h "},"kafka/数据清理.html":{"url":"kafka/数据清理.html","title":"数据清理","keywords":"","body":"数据日志清理有三种策略 基于时间 基于数据文件总大少 基于偏移量 关于基于偏移量的日志清理 [root@centos2 bin]# ll /usr/local/kafka total 588 drwxr-xr-x. 3 root root 4096 Apr 13 15:48 bin 命令位置 drwxr-xr-x. 3 root root 4096 Apr 13 15:13 config 配置位置 drwxr-xr-x. 2 root root 4096 Jun 3 2021 libs -rw-r--r--. 1 root root 14515 Apr 14 2021 LICENSE drwxr-xr-x. 2 root root 4096 Apr 14 2021 licenses drwxr-xr-x. 2 root root 389120 Apr 13 15:14 logs -rw-r--r--. 1 root root 953 Apr 14 2021 NOTICE -rw-r--r--. 1 root root 153405 Jun 7 2021 server.log drwxr-xr-x. 2 root root 4096 Apr 14 2021 site-docs -rw-r--r--. 1 root root 11469 Jun 4 2021 zk.log zookeeper的配置并启动服务 # /usr/local/kafka/config/server.properties ==kakfa 配置文件 # /usr/local/zookeeper/conf/zoo.cfg ==zookeeper 配置文件，默认是没有这个，这个文件是安装后重命名而来 # /usr/local/zookeeper/bin/zkServer.sh start / stop / status ==zookeeper 启动命令 # nohup /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties & == kafka 后台启动命令 # 3888：选举leader使用 # 2888：集群内机器通讯使用（Leader监听此端口） [root@centos2 conf]# cat /usr/local/zookeeper/conf/zoo.cfg |grep -v \"^#\" |grep -v \"^$\" tickTime=2000 initLimit=10 syncLimit=5 dataDir=/data/zookeeper clientPort=2181 server.1=192.168.1.160:2888:3888 server.2=192.168.1.250:2888:3888 # 修改好配置启动服务 [root@centos2 conf]# /usr/local/zookeeper/bin/zkServer.sh start 修改kafka配置并启动服务 [root@centos2 kafka-logs_9093]# cat /usr/local/kafka/config/server_9093.properties |grep -v \"^#\"|grep -v \"^$\" broker.id=3 这个是当前kafka节点的标识，下一操作进入zookeeper cli查询当前有啥broker时候就是看到这个id数字3 listeners=PLAINTEXT://192.168.1.160:9093 advertised.listeners=PLAINTEXT://192.168.1.160:9093 host.name=192.168.1.160 num.network.threads=3 num.io.threads=8 socket.send.buffer.bytes=102400 socket.receive.buffer.bytes=102400 socket.request.max.bytes=104857600 queued.max.requests =1000 log.dirs=/tmp/kafka-logs_9093 这个文件目录就是kafka存放数据的位置，这个目录下是topic-partition的文件夹，里面的.log就是数据文件 num.partitions=1 num.recovery.threads.per.data.dir=1 offsets.topic.replication.factor=1 transaction.state.log.replication.factor=1 transaction.state.log.min.isr=1 log.retention.hours=168 数据文件保留多少个小时清理，默认168小时7天时间 log.retention.bytes=107374182400 数据文件最大的大少，大过这个设定值就清理旧数据，这里100G log.segment.bytes=2048 每个数据段文件的大少默认是1G这里为了测试调整成了2K log.retention.check.interval.ms=300000 数据文件保留多久检测一遍这里是五分钟 zookeeper.connect=192.168.1.160:2181 这里多个值逗号分隔说明是几台kafka连在一起组成集群 # zookeeper.connect=192.168.1.160:2181,192.168.1.250:2181 两台组成集群时候，这里不一样，其他一样 zookeeper.connection.timeout.ms=18000 group.initial.rebalance.delay.ms=0 # 配置好就停止再启动kafka [root@centos2 kafka-logs_9093]# /usr/local/kafka/bin/kafka-server-stop.sh /usr/local/kafka/config/server_9093.properties [root@centos2 kafka-logs_9093]# /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server_9093.properties 创建topic并设置partition [root@centos2 bin]# /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper 192.168.1.160:2181 --replication-factor 3 --partitions 5 --topic click_log WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both. Error while executing topic command : Replication factor: 3 larger than available brokers: 1. [2022-04-14 11:10:38,070] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1. (kafka.admin.TopicCommand$) -- 警告:由于度量名称的限制，带有句号('.')或下划线('_')的主题可能会发生冲突。为了避免问题，最好使用其中之一，但不要两者都使用 -- 可用的broker没有三个，所以去zookeeper去查看情况 # 查看zookeeper的brokers的数量，只查到了[3]，和上面配置的broker.id=3一致，只有一个，所以只能 [root@centos2 bin]# pwd /usr/local/zookeeper/bin [root@centos2 bin]# zkCli.sh Connecting to localhost:2181 [zk: localhost:2181(CONNECTED) 0] ls ls [-s] [-w] [-R] path [zk: localhost:2181(CONNECTED) 1] ls / [admin, brokers, cluster, config, consumers, controller, controller_epoch, feature, isr_change_notification, latest_producer_id_block, log_dir_event_notification, zookeeper] [zk: localhost:2181(CONNECTED) 2] ls /brokers [ids, seqid, topics] [zk: localhost:2181(CONNECTED) 3] ls /brokers/ids [3] [root@centos2 bin]# /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper 192.168.1.160:2181 --replication-factor 1 --partitions 5 --topic click_log 查看topic情况 [root@centos2 bin]# /usr/local/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.1.160:2181 __consumer_offsets click_log 删除topic [root@centos2 bin]# /usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper 192.168.1.160:2181 --topic xxxx 查看partition情况 [root@centos2 bin]# /usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper 192.168.1.160:2181 --topic click_log Topic: click_log TopicId: nKt_W0ceRV62lVKj1QVRmw PartitionCount: 5 ReplicationFactor: 1 Configs: Topic: click_log Partition: 0 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log Partition: 1 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log Partition: 2 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log Partition: 3 Leader: 3 Replicas: 3 Isr: 3 Topic: click_log Partition: 4 Leader: 3 Replicas: 3 Isr: 3 生产数据 命令行生产数据 [root@centos2 bin]# /usr/local/kafka/bin/kafka-console-producer.sh --broker-list 192.168.1.160:9093 --topic click_log > hello world 1 > hello world 2 shell脚本批量生成数据(producer.sh) #!/bin/bash echo ---------------生产kafka数据---------------- read -p \"请输入起始数值：\" start_number read -p \"请输入增加长度：\" length #相应Ctrl+C中断 trap 'onCtrlC' INT function onCtrlC(){ echo 'Ctrl + C is captured' exit 1 } line=50 jlength=$[length/line] mod=$[length%line] if [ mod > 0 ];then jlength=$[jlength+1] fi for ((j=0; j> /tmp/kafka-tmp-data.shell.txt done cat /tmp/kafka-tmp-data.shell.txt |/usr/local/kafka/bin/kafka-console-producer.sh --broker-list 192.168.1.160:9093 --topic click_log rm -rf /tmp/kafka-tmp-data.shell.txt done echo -----------------完成---------------- 查看总偏移量 [root@centos2 bin]# /usr/local/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell --topic click_log --time -1 --broker-list 192.168.1.160:9093 click_log:0:0 click_log:1:0 click_log:2:0 click_log:3:0 click_log:4:0 # 也可以指定partition --partitions 0 消费数据 [root@centos2 bin]# /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server 192.168.1.160:9093 --from-beginning --topic click_log --group 0 # 给这个命令行消费起一个消费组名字 --group 0 #注意： 如果你用了指定了不同消费组名字来消费数据，只要是数据没被删除的，每个消费者名字都会从头拿到这些数据 查看组消费情况 查看消费组有那些 [root@centos2 bin]# /usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.1.160:9093 --list 指定消费组查看其数据情况 [root@centos2 bin]# /usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.1.160:9093 --describe --group 0 执行清理已消费数据 #!/bin/bash # 由于环境变量问题，定时任务需要刷新一下crontab的环境变量来解决 source /etc/profile offsetjsonPath=\"/usr/local/kafka/json\" offsetjsonFile=$offsetjsonPath\"/offset.json\" offsetCurrentFile=$offsetjsonPath\"/offset.txt\" if [ ! -d \"$offsetjsonPath\" ];then mkdir -p $offsetjsonPath fi echo '{ \"partitions\":[ {\"topic\": \"click_log\",\"partition\": 0,\"offset\": ##click_log__0##}, {\"topic\": \"click_log\",\"partition\": 1,\"offset\": ##click_log__1##}, {\"topic\": \"click_log\",\"partition\": 2,\"offset\": ##click_log__2##}, {\"topic\": \"click_log\",\"partition\": 3,\"offset\": ##click_log__3##}, {\"topic\": \"click_log\",\"partition\": 4,\"offset\": ##click_log__4##}, {\"topic\": \"click_log\",\"partition\": 5,\"offset\": ##click_log__5##}, {\"topic\": \"click_log\",\"partition\": 6,\"offset\": ##click_log__6##}, {\"topic\": \"click_log\",\"partition\": 7,\"offset\": ##click_log__7##}, {\"topic\": \"click_log\",\"partition\": 8,\"offset\": ##click_log__8##}, {\"topic\": \"click_log_1\",\"partition\": 0,\"offset\": ##click_log_1__0##}, {\"topic\": \"click_log_1\",\"partition\": 1,\"offset\": ##click_log_1__1##}, {\"topic\": \"click_log_1\",\"partition\": 2,\"offset\": ##click_log_1__2##}, {\"topic\": \"click_log_1\",\"partition\": 3,\"offset\": ##click_log_1__3##}, {\"topic\": \"click_log_1\",\"partition\": 4,\"offset\": ##click_log_1__4##}, {\"topic\": \"click_log_1\",\"partition\": 5,\"offset\": ##click_log_1__5##} ], \"version\": 1 } ' > $offsetjsonFile /usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 192.168.1.160:9093 --describe --group 0 |awk 'NR==3,NR==15'|awk '{print \"##\"$2\"__\"$3\"##\",$4}' > $offsetCurrentFile cat $offsetCurrentFile |while read line do array=(${line}) sed -i \"s/${array[0]}/${array[1]}/g\" $offsetjsonFile done if grep -q \"##\" $offsetjsonFile then echo \"It cannot be cleaned up because there are unreplaced offsets(因为存在未替换的偏移量不能进行清理)\" else /usr/local/kafka/bin/kafka-delete-records.sh --bootstrap-server 192.168.1.160:9093 -offset-json-file $offsetjsonFile fi # 1.生产1100数据，并消费完成 # 2.生产1100数据，不消费 # 3.目前总偏移量2200，1100属于消费，1100属于未消费，人为给每个partition都剩余一条记录，得出下面要清理的offser.json，并执行delete操作 # 4.清理后看下图发现，LAG未消费数据显示还是1100，但实际消费出来的仅仅只有我们剩余的8条（9个partition其中一个为0），也就是说删除数据，组的消费记录偏移量不会被修改，只有消费组消费的情况和生产数据才会改变这个LAG值 [root@centos2 ~]# cat /usr/local/kafka/json/offset.txt ##click_log__0## 299 ##click_log__1## 249 ##click_log__2## 0 ##click_log__3## 299 ##click_log__4## 299 ##click_log__5## 299 ##click_log__6## 199 ##click_log__7## 299 ##click_log__8## 149 ##click_log_1__0## 0 ##click_log_1__1## 0 ##click_log_1__2## 0 ##click_log_1__3## 0 ##click_log_1__4## 0 ##click_log_1__5## 0 "},"kafka/PHP生产者和消费者.html":{"url":"kafka/PHP生产者和消费者.html","title":"PHP生产者和消费者","keywords":"","body":"PHP消费者 高级消费者 $kafkaConf = $config['kafka']; $conf = new RdKafka\\Conf(); // 当有新的消费进程加入或者退出消费组时，kafka 会自动重新分配分区给消费者进程，这里注册了一个回调函数，当分区被重新分配时触发 $conf->setRebalanceCb(function (RdKafka\\KafkaConsumer $kafka, $err, array $partitions = null) { switch ($err) { case RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS: var_dump('log:kafkaRebalance',\"Assign\"); $kafka->assign($partitions); break; case RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS: var_dump('log:kafkaRebalance',\"Revoke\"); $kafka->assign(NULL); break; default: throw new \\Exception($err); } }); $conf->set('group.id', $kafkaConf['group.id']);//配置groud.id 具有相同 group.id 的consumer 将会处理不同分区的消息，所以同一个组内的消费者数量如果订阅了一个topic， 那么消费者进程的数量多于这个topic 分区的数量是没有意义的。 $conf->set('metadata.broker.list', $kafkaConf['metadata.broker.list']);//添加 kafka集群服务器地址 $topicConf = new RdKafka\\TopicConf(); $topicConf->set('auto.offset.reset', 'smallest');//当没有初始偏移量时，从哪里开始读取 $conf->setDefaultTopicConf($topicConf);// Set the configuration to use for subscribed/assigned topics $consumer = new RdKafka\\KafkaConsumer($conf); $consumer->subscribe(['click_log_1']); // 让消费者订阅log 主题，自动分配partitions while (true) { $msg_kfk = $consumer->consume(2000); /设置2s为超时 switch ($msg_kfk->err) { case RD_KAFKA_RESP_ERR_NO_ERROR: // 读取kafka中数据 $message = json_decode($msg_kfk->payload, true);// 收到消息，进行处理@TODO break; case RD_KAFKA_RESP_ERR__PARTITION_EOF: $canExecuteSql = true; //var_dump('log:kafka',\"No more messages; will wait for more\"); break; case RD_KAFKA_RESP_ERR__TIMED_OUT: $canExecuteSql = true; //var_dump('log:kafka',\"Timed out \".json_encode($hold_msg)); break; default: $canExecuteSql = true; $restartNumber = -1; var_dump('log:kafkaDefaultException','errstr['.$msg_kfk->errstr().'],errcode['.$msg_kfk->err.']'); break; } } PHP生产者 rdkafke https://github.com/edenhill/librdkafka https://github.com/arnaud-lb/php-rdkafka $conf = new RdKafka\\Conf(); $conf->set('metadata.broker.list', '192.168.1.160:9093'); //If you need to produce exactly once and want to keep the original produce order, uncomment the line below //$conf->set('enable.idempotence', 'true'); $producer = new RdKafka\\Producer($conf); $topic = $producer->newTopic(\"click_log\"); for ($i = 0; $i produce(RD_KAFKA_PARTITION_UA, 0, \"bean-Message $i\")); $producer->poll(0); } for ($flushRetries = 0; $flushRetries flush(10000); if (RD_KAFKA_RESP_ERR_NO_ERROR === $result) { break; } } if (RD_KAFKA_RESP_ERR_NO_ERROR !== $result) { throw new \\RuntimeException('Was unable to flush, messages might be lost!'); } nmred/kafka-php https://packagist.org/packages/nmred/kafka-php https://github.com/weiboad/kafka-php $ composer require nmred/kafka-php require '../vendor/autoload.php'; date_default_timezone_set('PRC'); for ($i=100;$i>0;$i--){ $config = \\Kafka\\ProducerConfig::getInstance(); $config->setMetadataRefreshIntervalMs(10000); $config->setMetadataBrokerList('192.168.1.160:9093'); $config->setBrokerVersion('2.8.0');//要查服务器安装的是啥版本 $config->setRequiredAck(1); $config->setIsAsyn(false);//true的时候一直发第一条 $config->setProduceInterval(500); $array = []; //for ($i=100;$i>0;$i--) { $array[] = [ 'topic' => 'click_log', 'value' => 'beantest....message-.' . $i, 'key' => 'testkey' ]; //} $producer = new \\Kafka\\Producer(function() use ($array) { return $array; }); $producer->success(function($result) { var_dump($result); }); $producer->error(function($errorCode) { var_dump($errorCode); }); var_dump($producer->send(true)); } "},"kafka/其他.html":{"url":"kafka/其他.html","title":"其他","keywords":"","body":"命令行操作kafka，输入sh回传即可看命令参数 [root@centos2 bin]# kafka-topics.sh Create, delete, describe, or change a topic. Option Description ------ ----------- --alter Alter the number of partitions, replica assignment, and/or configuration for the topic. --at-min-isr-partitions if set when describing topics, only show partitions whose isr count is equal to the configured minimum. Not supported with the --zookeeper option. --bootstrap-server to. In case of providing this, a direct Zookeeper connection won't be required. --command-config passed to Admin Client. This is used only with --bootstrap-server option ...... [root@centos2 ~]# cd /usr/local/kafka/bin [root@centos2 bin]# ll total 196 -rwxr-xr-x. 1 root root 1423 Apr 14 2021 connect-distributed.sh -rwxr-xr-x. 1 root root 1396 Apr 14 2021 connect-mirror-maker.sh -rwxr-xr-x. 1 root root 1420 Apr 14 2021 connect-standalone.sh -rwxr-xr-x. 1 root root 861 Apr 14 2021 kafka-acls.sh -rwxr-xr-x. 1 root root 873 Apr 14 2021 kafka-broker-api-versions.sh -rwxr-xr-x. 1 root root 860 Apr 14 2021 kafka-cluster.sh -rwxr-xr-x. 1 root root 864 Apr 14 2021 kafka-configs.sh -rwxr-xr-x. 1 root root 945 Apr 14 2021 kafka-console-consumer.sh -rwxr-xr-x. 1 root root 944 Apr 14 2021 kafka-console-producer.sh -rwxr-xr-x. 1 root root 871 Apr 14 2021 kafka-consumer-groups.sh -rwxr-xr-x. 1 root root 948 Apr 14 2021 kafka-consumer-perf-test.sh -rwxr-xr-x. 1 root root 871 Apr 14 2021 kafka-delegation-tokens.sh -rwxr-xr-x. 1 root root 869 Apr 14 2021 kafka-delete-records.sh -rwxr-xr-x. 1 root root 866 Apr 14 2021 kafka-dump-log.sh -rwxr-xr-x. 1 root root 863 Apr 14 2021 kafka-features.sh -rwxr-xr-x. 1 root root 870 Apr 14 2021 kafka-leader-election.sh -rwxr-xr-x. 1 root root 863 Apr 14 2021 kafka-log-dirs.sh -rwxr-xr-x. 1 root root 873 Apr 14 2021 kafka-metadata-shell.sh -rwxr-xr-x. 1 root root 862 Apr 14 2021 kafka-mirror-maker.sh -rwxr-xr-x. 1 root root 886 Apr 14 2021 kafka-preferred-replica-election.sh -rwxr-xr-x. 1 root root 959 Apr 14 2021 kafka-producer-perf-test.sh -rwxr-xr-x. 1 root root 874 Apr 14 2021 kafka-reassign-partitions.sh -rwxr-xr-x. 1 root root 874 Apr 14 2021 kafka-replica-verification.sh -rwxr-xr-x. 1 root root 10329 Apr 14 2021 kafka-run-class.sh -rwxr-xr-x. 1 root root 1376 Apr 14 2021 kafka-server-start.sh -rwxr-xr-x. 1 root root 1361 Apr 14 2021 kafka-server-stop.sh -rwxr-xr-x. 1 root root 860 Apr 14 2021 kafka-storage.sh -rwxr-xr-x. 1 root root 945 Apr 14 2021 kafka-streams-application-reset.sh -rwxr-xr-x. 1 root root 863 Apr 14 2021 kafka-topics.sh -rwxr-xr-x. 1 root root 958 Apr 14 2021 kafka-verifiable-consumer.sh -rwxr-xr-x. 1 root root 958 Apr 14 2021 kafka-verifiable-producer.sh -rw-------. 1 root root 37842 Oct 13 15:06 nohup.out -rwxr-xr-x. 1 root root 1714 Apr 14 2021 trogdor.sh drwxr-xr-x. 2 root root 4096 Apr 14 2021 windows -rwxr-xr-x. 1 root root 867 Apr 14 2021 zookeeper-security-migration.sh -rwxr-xr-x. 1 root root 1393 Apr 14 2021 zookeeper-server-start.sh -rwxr-xr-x. 1 root root 1366 Apr 14 2021 zookeeper-server-stop.sh -rwxr-xr-x. 1 root root 1019 Apr 14 2021 zookeeper-shell.sh 查看kafka版本和broker版本 [root@centos2 kafka]# find /usr/local/kafka/libs/ -name \\*kafka_\\* | head -1 | grep -o '\\kafka[^\\n]*' kafka/libs/kafka_2.13-2.8.0-test-sources.jar # 2.13是Scala版本，2.8.0是Kafka版本。 /usr/local/kafka/bin/kafka-broker-api-versions.sh --version 2.8.0 (Commit:ebb1d6e21cc92130) 查看端口情况 [root@centos2 bin]# netstat -tunlp|grep 9093 tcp 0 0 ::ffff:192.168.1.160:9093 :::* LISTEN 1765/java [root@centos2 bin]# netstat -tunlp|grep 2181 tcp 0 0 :::2181 :::* LISTEN 1275/java 删除topic /usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper 192.168.1.160:2181 --topic bean_log Topic bean_log is marked for deletion. Note: This will have no impact if delete.topic.enable is not set to true. /usr/local/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.1.160:2181 __consumer_offsets click_log click_test test 对名为click_log的topic，partition扩展到6个 [root@centos2 bin]# /usr/local/kafka/bin/kafka-topics.sh --alter --zookeeper 192.168.1.160:2181 --partitions 9 --topic click_log WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected Adding partitions succeeded! __consumer_offsets这个特殊的topic [root@centos2 bin]# /usr/local/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.1.160:2181 __consumer_offsets [root@centos2 bin]# kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server 192.168.1.160:9093 --from-beginning --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" (组名为anna和0的按理) [anna,click_log,4]::OffsetAndMetadata(offset=50, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [anna,click_log,0]::OffsetAndMetadata(offset=200, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [anna,click_log,3]::OffsetAndMetadata(offset=100, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [anna,click_log,8]::OffsetAndMetadata(offset=50, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [anna,click_log,2]::OffsetAndMetadata(offset=100, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [anna,click_log,7]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1649950575701,expireTimestamp=None) [anna,click_log,5]::OffsetAndMetadata(offset=100, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [anna,click_log,6]::OffsetAndMetadata(offset=200, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [anna,click_log,1]::OffsetAndMetadata(offset=150, leaderEpoch=Optional[0], metadata=, commitTimestamp=1649950575701, expireTimestamp=None) [0,click_log,4]::OffsetAndMetadata(offset=300, leaderEpoch=Optional[1], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,0]::OffsetAndMetadata(offset=300, leaderEpoch=Optional[1], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,3]::OffsetAndMetadata(offset=400, leaderEpoch=Optional[2], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,8]::OffsetAndMetadata(offset=150, leaderEpoch=Optional[1], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,2]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,7]::OffsetAndMetadata(offset=300, leaderEpoch=Optional[2], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,5]::OffsetAndMetadata(offset=300, leaderEpoch=Optional[2], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,6]::OffsetAndMetadata(offset=200, leaderEpoch=Optional[1], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [0,click_log,1]::OffsetAndMetadata(offset=250, leaderEpoch=Optional[2], metadata=, commitTimestamp=1649961789714, expireTimestamp=None) [anna,click_log,4]::NULL [anna,click_log,0]::NULL [anna,click_log,3]::NULL [anna,click_log,8]::NULL [anna,click_log,2]::NULL [anna,click_log,7]::NULL [anna,click_log,5]::NULL [anna,click_log,6]::NULL [anna,click_log,1]::NULL # NULL表示offset过期了 也就是墓碑消息 offset为什么会有墓碑消息? 因为offset本身也会过期清理.受offsets.retention.minutes 这个配置的影响 看下官网介绍 After a consumer group loses all its consumers (i.e. becomes empty) its offsets will be kept for this retention period before getting discarded. For standalone consumers (using manual assignment), offsets will be expired after the time of last commit plus this retention period. 当group里的consumer全部下线后过offsets.retention.minutes 时间后offset就会被删除 val OffsetsRetentionMinutes: Int = 7 * 24 * 60 // 默认7天 默认2.0之前是1天,2.0及以后是7天 这个官方真是..要么就改为2天,结果直接改为7天,改动不可谓不大,而且active的group不会过期 "},"php/tars.html":{"url":"php/tars.html","title":"tars","keywords":"","body":"tars docker下搭建指引 https://tarscloud.github.io/TarsDocs_en/installation/docker.html 使用手册 https://doc.tarsyun.com/ docker-compose 把框架搭建起来 概要说明: tarscloud/framework:v{x.y.y} 部署一主, 多从 tarscloud/framework:v{x.y.y} 以--net=host 的方式启动, 即和宿主机相同网络 节点应用服务器使用 tarscloud/tars-node:latest, 也以--net=host 方式启动 tarscloud/tars-node 有多个不同的标签如下: tarscloud/tars-node:stable, tarscloud/tars-node:latest, tarscloud/tars-node:full, 全环境, 即 jdk, php, nodejs 的运行时环境都已经安装 tarscloud/tars-node:cpp, 跑 cpp/go 服务 tarscloud/tars-node:java, 安装了 jdk tarscloud/tars-node:nodejs, 安装了 nodejs tarscloud/tars-node:php, 安装了 php # 指定compose文件并项目名字，默认是文件夹目录名字 $ docker-compose -f docker-compose-tars.yml -p tars up -d # 把所需要的服务都写到compose文件里 $ vim /f/www/dokcer-compose-tars.yml version: \"3\" services: mysql: image: mysql:5.6 container_name: tars-mysql ports: - \"3307:3306\" restart: always environment: MYSQL_ROOT_PASSWORD: \"123456\" volumes: - ./data/tars_mysql:/var/lib/mysql:rw # - ./source/Shanghai:/etc/localtime networks: internal: ipv4_address: 172.27.1.2 framework: image: tarscloud/framework:v2.4.14 container_name: tars-framework ports: - \"3000:3000\" restart: always networks: internal: ipv4_address: 172.27.1.3 environment: MYSQL_HOST: \"172.27.1.2\" MYSQL_ROOT_PASSWORD: \"123456\" MYSQL_USER: \"root\" MYSQL_PORT: 3307 REBUILD: \"false\" INET: eth0 SLAVE: \"false\" volumes: - ./data/tars_framework:/data/tars:rw # - ./source/Shanghai:/etc/localtime depends_on: - mysql node: image: tarscloud/tars-node:latest container_name: tars-node restart: always networks: internal: ipv4_address: 172.27.1.5 volumes: - ./data/tars_node:/data/tars:rw # - ./source/Shanghai:/etc/localtime environment: INET: eth0 WEB_HOST: http://172.27.1.3:3000 ports: - \"9000-9010:9000-9010\" depends_on: - framework networks: internal: driver: bridge ipam: config: - subnet: 172.27.1.0/16 PHP-HTTP-SERVER 目录结构 ├─ tars-php-hello-world 弄一个hello world的demo │ ├─ scripts 存储业务所需要的脚本 │ │ └─ tars2php.sh 负责的就是根据tars文件,生成客户端所需要的代码 │ ├─ src 业务逻辑所在的目录 │ │ ├─ component 存储Controller的基础类,方便所有的Controller公用 │ │ ├─ conf 业务需要的配置, 如果从平台下发配置,默认也会写入到这个文件夹中 │ │ ├─ controller MVC模型中的C层 │ │ ├─ servant 使用tars2php生成的client端的代码 │ │ ├─ composer.json 说明项目的依赖情况 │ │ ├─ index.php 整个服务的入口文件可自定义,但是必须要更改平台上的私有模板,增加entrance字段在server下面 │ │ └─ services.php 声明整个项目的基础namespaceName │ └─ tars │ │ ├─ example.tars 这个tcp服务所依赖 │ │ ├─ hello.proto.php 这个tcp服务所依赖 │ │ └─ tars.client.proto.php 生成servant下代码所必须的 开发 部署 添加模板 由于我们当前的是http服务，所以需要指定tars模板为protocolName=http,复制tars.tarsphp.default然后再server标签的最尾部追加，其余内容不变 ... ... ... protocolName=http //复制tars.tarsphp.default粘贴后只需要加这一距话在这里即可，其余不用动 添加应用 应用名和服务名称,注意,这个与下文中tars文件夹中的tars.proto.php 需要完全一致 服务类型为tars_php 模板为刚刚建立的http服务模板,默认不启用set 可用端口,填写服务器内网ip 端口类型为TCP !!!!协议类型HTTP服务必须选择非TARS!!!!!! 线程数对应SWOOLE的进程数 最大连接数和队列最大长度、队列超时时间,对php服务不生效 完成代码开发后,在src目录下执行 composer run-script deploy 会自动进行代码打包 "},"php/curl的ca证书.html":{"url":"php/curl的ca证书.html","title":"curl的ca证书","keywords":"","body":"curl的ca证书 作用 解决curl请求https时候提示没证书，可以选择下载证书并配置 Fatal error: Uncaught exception 'GuzzleHttp\\Exception\\RequestException' with message 'cURL error 60: SSL certificate problem: unable to get local issuer certificate (see http://curl.haxx.se/libcurl/c/libcurl-errors.html)' 不配置证书的解决方式，就是关了https验证 $guzzleClient = new \\GuzzleHttp\\Client(['verify' => false]); $guzzleClient->setDefaultOption('verify', false); $guzzleClient->get($url, ['verify' => false])->getBody()->__toString() $guzzleClient->request('GET',$url, ['verify' => false]); 获取地址 从Mozilla 提取得ca证书 https://curl.se/docs/caextract.html 直接获取 https://curl.se/ca/cacert.pem 下载完放到哪里 window Put it in : C:\\xampp\\php\\extras\\ssl\\cacert.pem Add this line to your php.ini curl.cainfo = \"C:\\xampp\\php\\extras\\ssl\\cacert.pem\" linux vim /usr/local/etc/php/php.ini curl.cainfo = /data/ssl/cacert.pem\" "},"software/phpstorm配置docker.html":{"url":"software/phpstorm配置docker.html","title":"phpstorm配置docker","keywords":"","body":"phpstorm应用docker中的php进行单元测试 让docker服务能被phpstorm感知 创建远程的PHPUnit 选择容器对应的docker-compose文件然后等待加载完毕 添加测试 右键执行 实质调用 [docker-compose://[F:\\docker-runtime\\docker-compose2.yml]:php/]:php /www/default/payment-api/vendor/phpunit/phpunit/phpunit --configuration /www/default/payment-api/phpunit.xml --filter \"/(Test\\\\Logic\\\\NoeticPkLogicTest::testMo)( .*)?$/\" --test-suffix NoeticPkLogicTest.php /www/default/payment-api/tests/logic --teamcity "},"software/fiddler对应用抓包.html":{"url":"software/fiddler对应用抓包.html","title":"fiddler对应用抓包","keywords":"","body":"fiddle对应用抓包 准备工作 下载Fiddler https://www.telerik.com/download/fiddler 安装Fiddler，运行并配置https Tools -> Options...->Https 勾选捕获Https连接，并安装https证书 配置运行远程连接及代理端口 PC 微信小程序音频 IOS端 记得关闭电脑防火墙，像微信上面对网络配置代理 下载针对移动版的 fiddlercertmaker （fiddler默认带的对于ios13.x经常抓不到包）- 未进行测试 如果抓不到包的话，可以试试 charles ，一般就能抓到 https://telerik-fiddler.s3.amazonaws.com/fiddler/addons/fiddlercertmaker.exe https://www.charlesproxy.com/ 设置 ->通用-> 描述文件 -> DO_NOT_TRUST_FiddlerRoot ->安装 设置 ->通用-> 关于本机 -> 证书信任设置 ->DO_NOT_TRUST_FiddlerRoot 打开开关 （IOS 10+后需要手动信任） 设置 -> 无线局域网 -> wifi名称后的 i 图标 ->HTTP代理 ->手动 -> 设置局域网服务器ip 和端口，不用填认证信息 几个比较流行的抓包/流量分析工具 Thor charles fiddler-everywhere fiddler HttpCanary wireshark 参考文章 https://juejin.cn/post/6920993581758939150 "},"software/远程开机远程控制.html":{"url":"software/远程开机远程控制.html","title":"远程开机远程控制","keywords":"","body":"解决以下问题 电脑停电后恢复开机 电脑没人开机 主板BIOS配置 && 安装toDesk软件 主板进入BIOS 点了电脑开机键立马一直按（F12 F2 F5 F8 F10 DEL ESC ）其中一个，直到有一个能让你进入到BIOS界面 DELL电脑配置案例 （新式的电脑支持Lan&wan远程启动） 实现断电后有点启动电脑：进入bios后，找到电源管理（power management）进行下图配置 想每天定时开机：进入bios后，找到电源管理（power management）进行下图配置 先通过手机远程开机设置，注意要disable（关掉) Deep Sleep Control（深度睡眠控制） 1、LAN 局域网(Local Area Network)接口，通俗讲就是路由和用户之间网线口； 2、WAN 广域网(Wide Area Network)，通俗讲就是和猫外部网连接的网线口； 3、WLAN无线局域网(Wireless LAN)，数据通过电磁波传输； 注意：下图中的LAN OR WLAN测试发现实际是外网和内网都能开的意思，虽然他实际意思不是 Lenovo电脑配置案例 （旧式的电脑支持仅支持Lan远程启动） 实现断电后有点启动电脑：进入bios后，找到电源管理（power management）进行下图配置 想每天定时开机：进入bios后，找到电源管理（power management）进行下图配置 先通过手机远程开机设置，注意要disable（关掉) ErP（能源相关产品） 最后远程开机效果 "},"software/macmini换硬盘装系统.html":{"url":"software/macmini换硬盘装系统.html","title":"macmini换硬盘装系统","keywords":"","body":"Mac Mini拆机更换SSD # 参考网址 https://mp.weixin.qq.com/s/uceStjltlDpxRnlQuW_2Tg https://jingyan.baidu.com/article/b907e627ac2fac46e7891c85.html https://mp.weixin.qq.com/s/raCGjqsaI0MmHT04USaepg 所需螺丝刀 六角螺丝刀，T7(带中孔的) T6 (可代可不带) 拆机换硬盘 1.翘后盖 2.带凸起的内六角螺丝，型号是 T7 带孔的螺丝刀，开盖后里面都是用T6螺丝 3.拆wifi链接头 4.拆散热风扇 5.拆主板固定螺丝 6.拆主板 7.拆电源 8.拆硬盘托 9.换硬盘 重装系统到新硬盘 这里用的是把旧硬盘放到啦硬盘盒子里，利用抹掉新硬盘（格式化的作用），恢复系统的方式 进入MacOs实用工具 因为我这个盒子用的是普通键盘，所以按Window+R代替Common+R。记得是大写的，所以其实要按Window+Shift+R，不行就Window+Shift+Alt+R四个键一起按。 把新硬盘进行抹掉操作 给新硬盘安装系统，这个过程很漫长，相当于是新下载一个系统，而且是十几G那种 安装完进入系统，发现系统版本太老又到AppStore搜索Macos进行升级 你在AppStore搜到的结果是和发布版本不同时间搜到的版本不一样 OS X 10.10 “Yosemite\" OS X 10.11 “El Capitan“ macOS 10.12 “Sierra“ macOS 10.13 “High Sierra” 2018年3月30日 macOS 10.14 \"Mojave\" 2018年9月25日 macOS 10.15 \"Catalina\" 2019年6月4日 macOS 11.0 \"Big Sur\" 2020年11月13日 macOS 12.0 “Monterey” 2021年10月26日 "}}